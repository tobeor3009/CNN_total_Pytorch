{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-1.5.9-py3-none-any.whl (527 kB)\n",
      "\u001b[K     |████████████████████████████████| 527 kB 10.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (2.5.0)\n",
      "Collecting future>=0.17.1\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[K     |████████████████████████████████| 829 kB 26.1 MB/s eta 0:00:01     |██████████████████████▏         | 573 kB 26.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (20.9)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (3.7.4.3)\n",
      "Collecting torchmetrics>=0.4.1\n",
      "  Downloading torchmetrics-0.7.0-py3-none-any.whl (396 kB)\n",
      "\u001b[K     |████████████████████████████████| 396 kB 28.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (1.19.5)\n",
      "Requirement already satisfied: torch>=1.7.* in /home/jegal/.local/lib/python3.6/site-packages (from pytorch-lightning) (1.10.0)\n",
      "Collecting setuptools==59.5.0\n",
      "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
      "\u001b[K     |████████████████████████████████| 952 kB 22.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /home/jegal/.local/lib/python3.6/site-packages (from pytorch-lightning) (4.62.3)\n",
      "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
      "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 29.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.1 in /home/jegal/.local/lib/python3.6/site-packages (from pytorch-lightning) (6.0)\n",
      "Collecting pyDeprecate==0.3.1\n",
      "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 34.0 MB/s eta 0:00:01    |██▋                             | 92 kB 33.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.25.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=17.0->pytorch-lightning) (2.4.7)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.36.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.12.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.17.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (2.0.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.4)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.34.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.30.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (4.0.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.26.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.1.0)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.7.*->pytorch-lightning) (0.8)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.2.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (191 kB)\n",
      "\u001b[K     |████████████████████████████████| 191 kB 24.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting asynctest==0.13.0\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting idna-ssl>=1.0\n",
      "  Downloading idna-ssl-1.1.0.tar.gz (3.4 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.2.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (159 kB)\n",
      "\u001b[K     |████████████████████████████████| 159 kB 50.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (270 kB)\n",
      "\u001b[K     |████████████████████████████████| 270 kB 30.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.2.0)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting charset-normalizer<3.0,>=2.0\n",
      "  Downloading charset_normalizer-2.0.10-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.4.1)\n",
      "Building wheels for collected packages: future, idna-ssl\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491059 sha256=a9ccd2204aaed2bda5d21ed5390c5bd874ef88a03806ccdcc003e10de6437021\n",
      "  Stored in directory: /home/jegal/.cache/pip/wheels/6e/9c/ed/4499c9865ac1002697793e0ae05ba6be33553d098f3347fb94\n",
      "  Building wheel for idna-ssl (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-py3-none-any.whl size=3160 sha256=547606fc1355f34e76d04072b6ae49b22f02223648ea7403d1abb9bb22b2934e\n",
      "  Stored in directory: /home/jegal/.cache/pip/wheels/6a/f5/9c/f8331a854f7a8739cf0e74c13854e4dd7b1af11b04fe1dde13\n",
      "Successfully built future idna-ssl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: setuptools, multidict, frozenlist, yarl, idna-ssl, charset-normalizer, asynctest, async-timeout, aiosignal, pyDeprecate, fsspec, aiohttp, torchmetrics, future, pytorch-lightning\n",
      "\u001b[33m  WARNING: The script normalizer is installed in '/home/jegal/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts futurize and pasteurize are installed in '/home/jegal/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 charset-normalizer-2.0.10 frozenlist-1.2.0 fsspec-2022.1.0 future-0.18.2 idna-ssl-1.1.0 multidict-5.2.0 pyDeprecate-0.3.1 pytorch-lightning-1.5.9 setuptools-59.5.0 torchmetrics-0.7.0 yarl-1.7.2\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gpu_number = \"2\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_number\n",
    "\n",
    "def windowing_brain(img_array, channel=3, return_uint8=True):\n",
    "    img_array = img_array.transpose((2, 0, 1))\n",
    "    slice_range = np.arange(img_array.shape[0])\n",
    "    slice_range = np.random.choice(slice_range, 32)\n",
    "    slice_range = np.sort(slice_range)\n",
    "    img_array = img_array[slice_range]\n",
    "    if channel == 1:\n",
    "        img_array = img_array + 40\n",
    "        img_array = img_array + 40\n",
    "        img_array = np.clip(img_array, 0, 160)\n",
    "        img_array = img_array / 160\n",
    "\n",
    "    elif channel == 3:\n",
    "        dcm0 = img_array - 5\n",
    "        dcm0 = np.clip(dcm0, 0, 50)\n",
    "        dcm0 = dcm0 / 50.\n",
    "\n",
    "        dcm1 = img_array + 0\n",
    "        dcm1 = np.clip(dcm1, 0, 80)\n",
    "        dcm1 = dcm1 / 80.\n",
    "\n",
    "        dcm2 = img_array + 20\n",
    "        dcm2 = np.clip(dcm2, 0, 200)\n",
    "        dcm2 = dcm2 / 200.\n",
    "\n",
    "        img_array = np.stack([dcm0, dcm1, dcm2], 0)\n",
    "        \n",
    "    if return_uint8: \n",
    "        return np.uint8(img_array * (2 ** 8 - 1))\n",
    "    \n",
    "    else: # the value is normalized to [0, 1]\n",
    "        return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data num 20162\n",
      "Total data num 2520\n",
      "Total data num 2442\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from src.data_loader.classification import ClassifyDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "\n",
    "batch_size = 2\n",
    "on_memory = False\n",
    "argumentation_proba = 0.8\n",
    "augmentation_policy_dict = {\n",
    "    \"positional\": True,\n",
    "    \"noise\": False,\n",
    "    \"elastic\":False,\n",
    "    \"brightness_contrast\": False,\n",
    "    \"color\": False,\n",
    "    \"to_jpeg\": False\n",
    "}\n",
    "image_channel_dict={\"image\": \"rgb\"}\n",
    "preprocess_input = windowing_brain\n",
    "target_size = (512, 512)\n",
    "interpolation = \"bilinear\"\n",
    "class_mode = \"binary\"\n",
    "# class_mode = \"categorical\"\n",
    "dtype=\"float32\"\n",
    "\n",
    "data_common_path = \"./datasets/1.normal_npy/\"\n",
    "\n",
    "train_image_path_list = glob(f\"{data_common_path}/train/*/*.npy\")\n",
    "valid_image_path_list = glob(f\"{data_common_path}/valid/*/*.npy\")\n",
    "test_image_path_list = glob(f\"{data_common_path}/test/*/*.npy\")\n",
    "\n",
    "label_list = os.listdir(f\"{data_common_path}/train/\")\n",
    "\n",
    "label_to_index_dict = {label:index for index, label in enumerate(label_list)}\n",
    "index_to_label_dict = {index:label for index, label in enumerate(label_list)}\n",
    "\n",
    "label_policy = lambda label: label_to_index_dict[label]\n",
    "def label_policy(label):\n",
    "    age, gender = label.split(\"_\")\n",
    "    age, gender = float(age), float(gender)\n",
    "    return [age, gender]\n",
    "\n",
    "common_arg_dict = {\n",
    "    \"label_policy\": label_policy,\n",
    "    \"argumentation_policy_dict\": augmentation_policy_dict,\n",
    "    \"image_channel_dict\": image_channel_dict,\n",
    "    \"preprocess_input\": preprocess_input,\n",
    "    \"target_size\": target_size,\n",
    "    \"interpolation\": interpolation,\n",
    "    \"class_mode\": class_mode,\n",
    "    \"dtype\": dtype\n",
    "}\n",
    "\n",
    "num_workers = min(batch_size // 2, 8)\n",
    "\n",
    "train_dataset = ClassifyDataset(image_path_list=train_image_path_list,\n",
    "                               on_memory=on_memory,\n",
    "                               argumentation_proba=argumentation_proba,\n",
    "                                **common_arg_dict\n",
    ")\n",
    "valid_dataset = ClassifyDataset(image_path_list=valid_image_path_list,\n",
    "                               on_memory=on_memory,\n",
    "                               argumentation_proba=0,\n",
    "                                **common_arg_dict\n",
    ")\n",
    "test_dataset = ClassifyDataset(image_path_list=test_image_path_list,\n",
    "                               on_memory=False,\n",
    "                               argumentation_proba=0,\n",
    "                               **common_arg_dict\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# F.cross_entropy\n",
    "# FM.accuracy\n",
    "class Classifier(pl.LightningModule):\n",
    "    def __init__(self, model, optimizer, loss_fun, metric, lr):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fun = loss_fun\n",
    "        self.metric = metric\n",
    "        self.lr = lr\n",
    "        self.act_layer = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        output = self.act_layer(output)\n",
    "        return output\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fun(logits, y)\n",
    "        age_average_precision, genender_acc = self.metric(logits, y)\n",
    "        metrics = {'train_precision': age_average_precision, 'train_acc': genender_acc, 'train_loss': loss}\n",
    "        self.log_dict(metrics, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fun(logits, y)\n",
    "        age_average_precision, genender_acc = self.metric(logits, y)\n",
    "        metrics = {'val_precision': age_average_precision,'val_acc': genender_acc, 'val_loss': loss}\n",
    "        self.log_dict(metrics)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fun(logits, y)\n",
    "        age_average_precision, genender_acc = self.metric(logits, y)\n",
    "        metrics = {'test_precision': age_average_precision, 'test_acc': genender_acc, 'test_loss': loss}\n",
    "        self.log_dict(metrics)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer(self.model.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------\n",
      "           Layer (type)                Input Shape         Param #     Tr. Param #\n",
      "===================================================================================\n",
      "               Conv3d-1       [1, 3, 32, 512, 512]          65,856          65,856\n",
      "          BatchNorm3d-2      [1, 64, 32, 256, 256]             128             128\n",
      "                 ReLU-3      [1, 64, 32, 256, 256]               0               0\n",
      "            MaxPool3d-4      [1, 64, 32, 256, 256]               0               0\n",
      "           Bottleneck-5      [1, 64, 16, 128, 128]         148,736         148,736\n",
      "           Bottleneck-6     [1, 256, 16, 128, 128]         144,128         144,128\n",
      "           Bottleneck-7     [1, 256, 16, 128, 128]         144,128         144,128\n",
      "           Bottleneck-8     [1, 256, 16, 128, 128]         674,304         674,304\n",
      "           Bottleneck-9        [1, 512, 8, 64, 64]         574,976         574,976\n",
      "          Bottleneck-10        [1, 512, 8, 64, 64]         574,976         574,976\n",
      "          Bottleneck-11        [1, 512, 8, 64, 64]         574,976         574,976\n",
      "          Bottleneck-12        [1, 512, 8, 64, 64]       2,692,096       2,692,096\n",
      "          Bottleneck-13       [1, 1024, 4, 32, 32]       2,296,832       2,296,832\n",
      "          Bottleneck-14       [1, 1024, 4, 32, 32]       2,296,832       2,296,832\n",
      "          Bottleneck-15       [1, 1024, 4, 32, 32]       2,296,832       2,296,832\n",
      "          Bottleneck-16       [1, 1024, 4, 32, 32]       2,296,832       2,296,832\n",
      "          Bottleneck-17       [1, 1024, 4, 32, 32]       2,296,832       2,296,832\n",
      "          Bottleneck-18       [1, 1024, 4, 32, 32]      10,758,144      10,758,144\n",
      "          Bottleneck-19       [1, 2048, 2, 16, 16]       9,181,184       9,181,184\n",
      "          Bottleneck-20       [1, 2048, 2, 16, 16]       9,181,184       9,181,184\n",
      "   AdaptiveAvgPool3d-21       [1, 2048, 2, 16, 16]               0               0\n",
      "              Linear-22                  [1, 2048]           4,098           4,098\n",
      "===================================================================================\n",
      "Total params: 46,203,074\n",
      "Trainable params: 46,203,074\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from src.model.net_3d.resnet import ResNet, BasicBlock, Bottleneck\n",
    "import torch\n",
    "import pytorch_model_summary\n",
    "\n",
    "base_model = ResNet(Bottleneck, [3, 4, 6, 3], [64, 128, 256, 512], n_input_channels=3, n_classes=2).cuda()\n",
    "print(pytorch_model_summary.summary(base_model, torch.zeros(1, 3, 32, 512, 512).cuda(), show_input=True))\n",
    "# base_model(torch.zeros(1, 1, 32, 512, 256).cuda).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.models import nf_resnet101 \n",
    "import torchmetrics\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam\n",
    "\n",
    "def loss_fun(logit, y):\n",
    "    logit_age = logit[..., 0]\n",
    "    y_age = y[0]\n",
    "    logit_gender = logit[..., 1]\n",
    "    y_gender = y[1].float()\n",
    "    age_loss = nn.L1Loss().cuda()(logit_age, y_age)\n",
    "    gender_loss = nn.BCELoss().cuda()(logit_gender, y_gender)\n",
    "        \n",
    "    return age_loss + gender_loss\n",
    "\n",
    "def metric(logit, y):\n",
    "    logit_age = logit[..., 0]\n",
    "    y_age = y[0]\n",
    "    logit_gender = logit[..., 1]\n",
    "    y_gender = y[1].int()\n",
    "    \n",
    "    age_average_precision = torchmetrics.MeanAbsoluteError().cuda()(logit_age, y_age)\n",
    "    genender_acc = torchmetrics.Accuracy().cuda()(logit_gender, y_gender)\n",
    "    \n",
    "    return age_average_precision, genender_acc\n",
    "\n",
    "logger = CSVLogger(\"logs\", name=\"brain_classification\")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='logs/',\n",
    "    filename='epoch{epoch:02d}-val_loss{val_loss:.2f}',\n",
    "    auto_insert_metric_name=False,\n",
    "    save_top_k=5, \n",
    ")\n",
    "\n",
    "model = Classifier(base_model, optimizer, loss_fun, metric, 1e-6).cuda()\n",
    "# model = Classifier.load_from_checkpoint(checkpoint_path=\"./logs/epoch03-val_loss0.14.ckpt\",\n",
    "#                                                                                  model=base_model,\n",
    "#                                                                                  optimizer=optimizer,\n",
    "#                                                                                  loss_fun=loss_fun,\n",
    "#                                                                                  metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\n",
      "  | Name      | Type    | Params\n",
      "--------------------------------------\n",
      "0 | model     | ResNet  | 46.2 M\n",
      "1 | act_layer | Sigmoid | 0     \n",
      "--------------------------------------\n",
      "46.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "46.2 M    Total params\n",
      "184.812   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16a7ed52c284252b4cc1377dc0d4d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=1, logger=logger, callbacks=[checkpoint_callback])\n",
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 성능\n",
    "- sex accuracy: 98 %\n",
    "- age: L1 distance -> age < 3 years\n",
    "    - age를 잘 맞추는 게 임상적으로 더 의미 있음.\n",
    "    \n",
    "- modeling\n",
    "    - Conv3D vs. CNN + Transformer\n",
    "        - Conv3D: 학습했을 때 3 살 내로 된다면?? -> 심플하니까\n",
    "        - 만약 잘못한다 -> CNN + Transformer\n",
    "- Augmentations\n",
    "    - geometric: flip, rotation \n",
    "    - blur, ...?\n",
    "    \n",
    "- 32 장 기준으로 만들기\n",
    "    - 32장 \n",
    "    - 32장 이상 -> 일정한 간격으로 32장 골라 쓰기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unused Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import shutil\n",
    "data_common_path = \"./datasets/1.normal_npy/\"\n",
    "os.makedirs(f\"{data_common_path}/train\", exist_ok=True)\n",
    "os.makedirs(f\"{data_common_path}/valid\", exist_ok=True)\n",
    "os.makedirs(f\"{data_common_path}/test\", exist_ok=True)\n",
    "\n",
    "data_path = glob(f\"{data_common_path}/*\")\n",
    "\n",
    "data_path_list = glob(f\"{data_common_path}/*\")[:-3]\n",
    "\n",
    "for data_path in tqdm(data_path_list):\n",
    "    source = os.path.basename(data_path)\n",
    "    npy_path_list = glob(f\"{data_path}/*.npy\") \n",
    "    random.shuffle(npy_path_list)\n",
    "    npy_num = len(npy_path_list)\n",
    "    train_num = math.ceil(npy_num * 0.8)\n",
    "    valid_num = math.ceil(npy_num * 0.9)\n",
    "    for npy_index, npy_path in enumerate(npy_path_list):\n",
    "        npy_basename = os.path.basename(npy_path)\n",
    "        if npy_index < train_num:\n",
    "            target = \"train\"\n",
    "        elif npy_index < valid_num:\n",
    "            target = \"valid\"\n",
    "        else:\n",
    "            target = \"test\"\n",
    "            \n",
    "        os.makedirs(f\"{data_common_path}/{target}/{source}\", exist_ok=True)    \n",
    "        new_npy_path = f\"{data_common_path}/{target}/{source}/{npy_basename}\"\n",
    "        shutil.move(npy_path, new_npy_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 512, 512)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = np.zeros((48,512,512))\n",
    "slice_range = np.arange(48)\n",
    "slice_range = np.random.choice(slice_range, 32)\n",
    "slice_range = np.sort(slice_range)\n",
    "\n",
    "temp[slice_range].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
